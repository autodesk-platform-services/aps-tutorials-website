The following apis should be added to the `DesignAutomation.js` file before the last line `module.exports = router;`

- StartWorkitem

This is where we actually start the Design Automation. This endpoint also uploads the input file to an OSS Bucket and define that the output should be saved at the same bucket. To help you identify the files, both input and output uses the same original file name, but with a suffix (input or output) plus a time stamp.

```js
/// <summary>
/// Direct To S3
/// ref : https://aps.autodesk.com/blog/new-feature-support-direct-s3-migration-inputoutput-files-design-automation
/// </summary>

const getObjectId = async (bucketKey, objectKey, req) => {
  try {
    let contentStream = _fs.createReadStream(req.file.path);
    let uploadResponse = await new ForgeAPI.ObjectsApi().uploadResources(
      bucketKey,
      {
        objectKey: objectKey,
        data: contentStream,
        length: req.file.size,
      },
      {
        useAcceleration: false,
        minutesExpiration: 20,
        onUploadProgress: (data) => console.warn(data),
      },
      req.oauth_client,
      req.oauth_token
    );
    console.log(uploadResponse[0].completed.objectId);
    return uploadResponse[0].completed.objectId;
  } catch (ex) {
    console.error(ex);
    return res.status(500).json({
      diagnostic: "Failed to upload file for workitem",
    });
  }
};

/// <summary>
/// Start a new workitem
/// </summary>
router.post(
  "/aps/designautomation/workitems",
  multer({
    dest: "uploads/",
  }).single("inputFile"),
  async (/*StartWorkitem*/ req, res) => {
    const input = req.body;

    // basic input validation
    const workItemData = JSON.parse(input.data);
    const widthParam = parseFloat(workItemData.width);
    const heigthParam = parseFloat(workItemData.height);
    const activityName = `${Utils.NickName}.${workItemData.activityName}`;
    const browerConnectionId = workItemData.browerConnectionId;

    // save the file on the server
    const ContentRootPath = _path.resolve(_path.join(__dirname, "../.."));
    const fileSavePath = _path.join(
      ContentRootPath,
      _path.basename(req.file.originalname)
    );

    // upload file to OSS Bucket
    // 1. ensure bucket existis
    const bucketKey = Utils.NickName.toLowerCase() + "-designautomation";
    try {
      let payload = new ForgeAPI.PostBucketsPayload();
      payload.bucketKey = bucketKey;
      payload.policyKey = "transient"; // expires in 24h
      await new ForgeAPI.BucketsApi().createBucket(
        payload,
        {},
        req.oauth_client,
        req.oauth_token
      );
    } catch (ex) {
      // in case bucket already exists
    }
    // 2. upload inputFile
    const inputFileNameOSS = `${new Date()
      .toISOString()
      .replace(/[-T:\.Z]/gm, "")
      .substring(0, 14)}_input_${_path.basename(req.file.originalname)}`; // avoid overriding
    // prepare workitem arguments
    const bearerToken = ["Bearer", req.oauth_token.access_token].join(" ");
    // 1. input file
    const inputFileArgument = {
      url: await getObjectId(bucketKey, inputFileNameOSS, req),
      headers: { Authorization: bearerToken },
    };
    // 2. input json
    const inputJson = {
      width: widthParam,
      height: heigthParam,
    };
    const inputJsonArgument = {
      url:
        "data:application/json, " +
        JSON.stringify(inputJson).replace(/"/g, "'"),
    };
    // 3. output file
    const outputFileNameOSS = `${new Date()
      .toISOString()
      .replace(/[-T:\.Z]/gm, "")
      .substring(0, 14)}_output_${_path.basename(req.file.originalname)}`; // avoid overriding
    const outputFileArgument = {
      url: await getObjectId(bucketKey, outputFileNameOSS, req),
      verb: dav3.Verb.put,
      headers: { Authorization: bearerToken },
    };

    // prepare & submit workitem
    // the callback contains the connectionId (used to identify the client) and the outputFileName of this workitem
    const callbackUrl = `${config.credentials.webhook_url}/api/aps/callback/designautomation?id=${browerConnectionId}&outputFileName=${outputFileNameOSS}&inputFileName=${inputFileNameOSS}`;
    const workItemSpec = {
      activityId: activityName,
      arguments: {
        inputFile: inputFileArgument,
        inputJson: inputJsonArgument,
        outputFile: outputFileArgument,
        onComplete: {
          verb: dav3.Verb.post,
          url: callbackUrl,
        },
      },
    };
    let workItemStatus = null;
    try {
      const api = await Utils.dav3API(req.oauth_token);
      workItemStatus = await api.createWorkItem(workItemSpec);
    } catch (ex) {
      console.error(ex);
      return res.status(500).json({
        diagnostic: "Failed to create a workitem",
      });
    }
    res.status(200).json({
      workItemId: workItemStatus.id,
    });
  }
);
```

- OnCallback

When the workitem is done, Design Automation will callback our app (using the ngrok forwarding URL). This function will handle it and push a notification to the client (using socketIO).

```js
/// <summary>
/// Callback from Design Automation Workitem (onProgress or onComplete)
/// </summary>
router.post(
  "/aps/callback/designautomation",
  async (/*OnCallback*/ req, res) => {
    // your webhook should return immediately! we could use Hangfire to schedule a job instead
    // ALWAYS return ok (200)
    res.status(200).end();

    try {
      const socketIO = require("../server").io;

      // your webhook should return immediately! we can use Hangfire to schedule a job
      const bodyJson = req.body;
      socketIO.to(req.query.id).emit("onComplete", bodyJson);

      http.get(bodyJson.reportUrl, (response) => {
        //socketIO.to(req.query.id).emit('onComplete', response);
        response.setEncoding("utf8");
        let rawData = "";
        response.on("data", (chunk) => {
          rawData += chunk;
        });
        response.on("end", () => {
          socketIO.to(req.query.id).emit("onComplete", rawData);
        });
      });
      //socketIO.to(req.query.id).emit('downloadReport', bodyJson.reportUrl);

      const objectsApi = new ForgeAPI.ObjectsApi();
      const bucketKey = Utils.NickName.toLowerCase() + "-designautomation";
      if (bodyJson.status === "success") {
        try {
          //Complete the upload to S3
          await objectsApi.completeS3Upload(
            bucketKey,
            req.query.outputFileName,
            { uploadKey: req.query.uploadKey },
            { useAcceleration: false, minutesExpiration: 2 },
            req.oauth_client,
            req.oauth_token
          );
          //create a S3 presigned URL and send to client
          let response = await objectsApi.getS3DownloadURL(
            bucketKey,
            req.query.outputFileName,
            { useAcceleration: false, minutesExpiration: 15 },
            req.oauth_client,
            req.oauth_token
          );
          socketIO.to(req.query.id).emit("downloadResult", response.body.url);
        } catch (ex) {
          console.error(ex);
          socketIO
            .to(req.query.id)
            .emit(
              "onComplete",
              "Failed to create presigned URL for outputFile.\nYour outputFile is available in your OSS bucket."
            );
        }
      }

      // delete the input file (we do not need it anymore)
      try {
        /*await*/
        objectsApi.deleteObject(
          bucketKey,
          req.query.inputFileName,
          req.oauth_client,
          req.oauth_token
        );
      } catch (ex) {
        console.error(ex);
      }
    } catch (ex) {
      console.error(ex);
    }
  }
);
```

- ClearAccount

```js
/// <summary>
/// Clear the accounts (for debugging purpouses)
/// </summary>
router.delete(
  "/aps/designautomation/account",
  async (/*ClearAccount*/ req, res) => {
    let api = await Utils.dav3API(req.oauth_token);
    // clear account
    await api.deleteForgeApp("me");
    res.status(200).end();
  }
);
```
